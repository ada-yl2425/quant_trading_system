{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03db1169-67f8-47f9-b537-8eaa25caccb2",
   "metadata": {
    "id": "03db1169-67f8-47f9-b537-8eaa25caccb2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "NnSQGhLBuSWc",
   "metadata": {
    "id": "NnSQGhLBuSWc"
   },
   "outputs": [],
   "source": [
    "class OutputConfig:\n",
    "    # 设置为True可以显示详细输出，False只显示关键信息\n",
    "    VERBOSE = False\n",
    "    SHOW_PROGRESS = True\n",
    "    SHOW_FEATURE_DETAILS = False\n",
    "    SHOW_TRAINING_DETAILS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ad6964-1fae-4141-a2ef-8f2cd5e512ee",
   "metadata": {
    "id": "f6ad6964-1fae-4141-a2ef-8f2cd5e512ee"
   },
   "source": [
    "# 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881d388-0e6c-4b97-b404-4ae2a65d7dd2",
   "metadata": {
    "id": "9881d388-0e6c-4b97-b404-4ae2a65d7dd2"
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, data_folder_path):\n",
    "        self.data_folder = Path(data_folder_path)\n",
    "        self.feature_data = None\n",
    "\n",
    "    def load_parquet_files(self):\n",
    "        parquet_files = list(self.data_folder.glob(\"*.parquet\"))\n",
    "        if not parquet_files:\n",
    "            raise ValueError(f\"在 {self.data_folder} 中没有找到parquet文件\")\n",
    "\n",
    "        features_dict = {}\n",
    "        for file_path in parquet_files:\n",
    "            feature_name = file_path.stem  # 获取文件名（不带扩展名）\n",
    "            try:\n",
    "                df = pd.read_parquet(file_path)\n",
    "                # 使用特征名作为列名前缀，避免合并时的列名冲突\n",
    "                df = df.add_prefix(f\"{feature_name}_\")\n",
    "                features_dict[feature_name] = df\n",
    "                print(f\"成功加载特征: {feature_name}, 形状: {df.shape}\")\n",
    "            except Exception as e:\n",
    "                print(f\"加载 {feature_name} 失败: {e}\")\n",
    "\n",
    "        return self.merge_features(features_dict)\n",
    "\n",
    "    def merge_features(self, features_dict):\n",
    "        if not features_dict:\n",
    "            raise ValueError(\"没有可用的特征数据\")\n",
    "\n",
    "        # 首先将所有DataFrame的索引统一为日期类型\n",
    "        for name, df in features_dict.items():\n",
    "            if df.index.name != 'date' and 'date' in df.columns:\n",
    "                df = df.set_index('date')\n",
    "\n",
    "            # 确保索引是日期类型\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            features_dict[name] = df.sort_index()\n",
    "\n",
    "        # 使用concat而不是merge来避免列名冲突\n",
    "        # 但需要确保所有DataFrame有相同的索引\n",
    "        all_data = []\n",
    "        for name, df in features_dict.items():\n",
    "            all_data.append(df)\n",
    "\n",
    "        # 使用outer连接合并所有数据\n",
    "        merged_data = pd.concat(all_data, axis=1, join='outer')\n",
    "\n",
    "        print(f\"合并后数据形状: {merged_data.shape}\")\n",
    "        return merged_data\n",
    "\n",
    "    def find_target_column(self, data):\n",
    "        # 查找包含 'ret_21' 的列，不区分大小写\n",
    "        target_cols = [col for col in data.columns if 'ret_21' in col.lower()]\n",
    "        if target_cols:\n",
    "            return target_cols[0]\n",
    "        else:\n",
    "            print(\"警告: 未找到目标变量列\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e0f879-11d2-481b-8b8b-09d24200366e",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266fcc8-58a5-45fc-879a-32c685b6b3a1",
   "metadata": {
    "id": "7266fcc8-58a5-45fc-879a-32c685b6b3a1"
   },
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "\n",
    "    def __init__(self, nan_threshold=0.8):\n",
    "        self.nan_threshold = nan_threshold\n",
    "        self.kept_features = []\n",
    "\n",
    "    def remove_high_nan_features(self, data):\n",
    "        # 移除超过阈值NaN比例的特征\n",
    "        if data.empty:\n",
    "            return data\n",
    "\n",
    "        nan_ratio = data.isnull().sum() / len(data)\n",
    "        features_to_keep = nan_ratio[nan_ratio <= self.nan_threshold].index.tolist()\n",
    "\n",
    "        # 记录被移除的特征\n",
    "        removed_features = set(data.columns) - set(features_to_keep)\n",
    "\n",
    "        self.kept_features = features_to_keep\n",
    "        return data[features_to_keep]\n",
    "\n",
    "    def safe_forward_fill(self, data):\n",
    "        # 前向填充，处理开头为NaN的情况\n",
    "        if data.empty:\n",
    "            return data\n",
    "\n",
    "        # 首先前向填充\n",
    "        data_filled = data.ffill()\n",
    "\n",
    "        # 检查是否还有NaN（出现在开头）\n",
    "        if data_filled.isnull().any().any():\n",
    "            print(\"检测到开头存在NaN，使用后向填充处理开头数据...\")\n",
    "            # 对于开头的NaN，使用后向填充（不会泄漏未来信息）\n",
    "            data_filled = data_filled.bfill()\n",
    "\n",
    "            # 如果还有NaN（全部为NaN的列），填充0\n",
    "            if data_filled.isnull().any().any():\n",
    "                print(\"使用0填充剩余的NaN值...\")\n",
    "                data_filled = data_filled.fillna(0)\n",
    "\n",
    "        return data_filled\n",
    "\n",
    "    def clean_data(self, data):\n",
    "        print(f\"原始数据形状: {data.shape}\")\n",
    "\n",
    "        # 移除高缺失率特征\n",
    "        data_cleaned = self.remove_high_nan_features(data)\n",
    "        print(f\"移除高缺失率特征后形状: {data_cleaned.shape}\")\n",
    "\n",
    "        # 安全填充\n",
    "        data_filled = self.safe_forward_fill(data_cleaned)\n",
    "        print(f\"填充后数据形状: {data_filled.shape}\")\n",
    "\n",
    "        # 检查是否还有NaN\n",
    "        remaining_nans = data_filled.isnull().sum().sum()\n",
    "        if remaining_nans > 0:\n",
    "            print(f\"警告: 数据中仍有 {remaining_nans} 个NaN值\")\n",
    "\n",
    "        return data_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c670901c-c8fc-43f2-a456-a1fd7dc17a01",
   "metadata": {},
   "source": [
    "## 宏观数据提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4fb09f-d37d-4857-9c02-ec1f3b413461",
   "metadata": {
    "id": "bd4fb09f-d37d-4857-9c02-ec1f3b413461"
   },
   "outputs": [],
   "source": [
    "class MacroDataEnhancer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.macro_features = []\n",
    "        self.downloaded_data = {}\n",
    "\n",
    "    def download_macro_data(self, start_date, end_date):\n",
    "        macro_tickers = {\n",
    "            'dollar_index': 'DX-Y.NYB',  # 美元指数\n",
    "            'vix': '^VIX',               # VIX波动率指数\n",
    "            'bond_yield_10y': '^TNX',    # 10年期国债收益率\n",
    "            'sp500': '^GSPC',            # S&P 500指数\n",
    "            'gold': 'GC=F',              # 黄金价格\n",
    "            'oil': 'CL=F'                # 原油价格\n",
    "        }\n",
    "\n",
    "        for name, ticker in macro_tickers.items():\n",
    "            try:\n",
    "                print(f\"正在下载 {name} 数据...\")\n",
    "\n",
    "                # 使用正确的yfinance下载方法\n",
    "                import yfinance as yf\n",
    "\n",
    "                # 下载数据\n",
    "                data = yf.download(\n",
    "                    ticker,\n",
    "                    start=start_date,\n",
    "                    end=end_date,\n",
    "                    progress=False,\n",
    "                    auto_adjust=True\n",
    "                )\n",
    "\n",
    "                if not data.empty:\n",
    "                    # 使用调整后的收盘价\n",
    "                    if 'Adj Close' in data.columns:\n",
    "                        macro_series = data['Adj Close']\n",
    "                    else:\n",
    "                        macro_series = data['Close']\n",
    "\n",
    "                    # 重命名序列\n",
    "                    macro_series.name = name\n",
    "                    self.downloaded_data[name] = macro_series\n",
    "                    print(f\"成功下载 {name} 数据，共 {len(macro_series)} 个数据点\")\n",
    "                else:\n",
    "                    print(f\"警告: {name} 数据为空\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"下载 {name} 失败: {str(e)}\")\n",
    "                # 如果下载失败，创建一个空的Series作为占位符\n",
    "                empty_series = pd.Series([], dtype=float, name=name)\n",
    "                self.downloaded_data[name] = empty_series\n",
    "\n",
    "    def add_all_macro_data(self, data, start_date, end_date):\n",
    "        self.download_macro_data(start_date, end_date)\n",
    "\n",
    "        enhanced_data = data.copy()\n",
    "        macro_data_added = 0\n",
    "\n",
    "        for macro_name, macro_series in self.downloaded_data.items():\n",
    "            if len(macro_series) == 0:\n",
    "                print(f\"跳过空的宏观数据: {macro_name}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # 确保索引类型一致\n",
    "                macro_series.index = pd.to_datetime(macro_series.index)\n",
    "                enhanced_data.index = pd.to_datetime(enhanced_data.index)\n",
    "\n",
    "                # 确保我们处理的是Series而不是DataFrame\n",
    "                if isinstance(macro_series, pd.DataFrame):\n",
    "                    print(f\"警告: {macro_name} 是DataFrame而不是Series，尝试提取第一列\")\n",
    "                    macro_series = macro_series.iloc[:, 0]  # 取第一列\n",
    "                    macro_series.name = macro_name\n",
    "\n",
    "                # 将Series转换为DataFrame进行合并\n",
    "                macro_df = pd.DataFrame({macro_name: macro_series})\n",
    "\n",
    "                # 合并宏观数据\n",
    "                enhanced_data = enhanced_data.merge(\n",
    "                    macro_df,\n",
    "                    left_index=True,\n",
    "                    right_index=True,\n",
    "                    how='left'\n",
    "                )\n",
    "                self.macro_features.append(macro_name)\n",
    "                macro_data_added += 1\n",
    "                print(f\"已添加宏观特征: {macro_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"添加宏观特征 {macro_name} 失败: {str(e)}\")\n",
    "\n",
    "        print(f\"宏观数据添加完成，成功添加 {macro_data_added} 个宏观特征\")\n",
    "        return enhanced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510d072-bdc5-4858-91b7-c5dc9c604d01",
   "metadata": {},
   "source": [
    "# 特征处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d1def-8d57-4e0a-8611-00f47515ca74",
   "metadata": {},
   "source": [
    "## 初步特征筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2368f03b-7f0e-4769-88d4-b9a5b01d6172",
   "metadata": {
    "id": "2368f03b-7f0e-4769-88d4-b9a5b01d6172"
   },
   "outputs": [],
   "source": [
    "class FeatureSelector:\n",
    "\n",
    "    def __init__(self, max_features=1000, correlation_threshold=0.01,\n",
    "                 mutual_info_threshold=0.01, variance_threshold=0.01):\n",
    "        self.max_features = max_features\n",
    "        self.correlation_threshold = correlation_threshold\n",
    "        self.mutual_info_threshold = mutual_info_threshold\n",
    "        self.variance_threshold = variance_threshold\n",
    "        self.selected_features = []\n",
    "\n",
    "    def calculate_feature_variance(self, data):\n",
    "        variances = data.var()\n",
    "        return variances\n",
    "\n",
    "    def calculate_target_correlation(self, data, target_col='ret_21D'):\n",
    "        correlations = {}\n",
    "        target = data[target_col]\n",
    "\n",
    "        for column in data.columns:\n",
    "            if column != target_col:\n",
    "                # Spearman相关系数，对异常值更稳健\n",
    "                valid_data = data[[column, target_col]].dropna()\n",
    "                if len(valid_data) > 10:\n",
    "                    corr, _ = spearmanr(valid_data[column], valid_data[target_col])\n",
    "                    correlations[column] = abs(corr) if not np.isnan(corr) else 0\n",
    "\n",
    "        return correlations\n",
    "\n",
    "    def calculate_mutual_information(self, data, target_col='ret_21D', sample_fraction=0.1):\n",
    "        # 抽样计算以节省时间\n",
    "        sample_data = data.sample(frac=sample_fraction, random_state=42) if len(data) > 1000 else data\n",
    "        sample_data = sample_data.dropna()\n",
    "\n",
    "        if len(sample_data) < 50:\n",
    "            return {}\n",
    "\n",
    "        X_sample = sample_data.drop(target_col, axis=1)\n",
    "        y_sample = sample_data[target_col]\n",
    "\n",
    "        # 只计算部分特征以节省时间\n",
    "        max_features_to_test = min(1000, len(X_sample.columns))\n",
    "        features_to_test = np.random.choice(X_sample.columns, max_features_to_test, replace=False)\n",
    "\n",
    "        mi_scores = {}\n",
    "        for feature in features_to_test:\n",
    "            try:\n",
    "                mi = mutual_info_regression(\n",
    "                    X_sample[[feature]].values.reshape(-1, 1),\n",
    "                    y_sample,\n",
    "                    random_state=42\n",
    "                )[0]\n",
    "                mi_scores[feature] = mi\n",
    "            except:\n",
    "                mi_scores[feature] = 0\n",
    "\n",
    "        return mi_scores\n",
    "\n",
    "    def select_features_static(self, data, target_col='ret_21D'):\n",
    "        \"\"\"静态特征选择\"\"\"\n",
    "        print(f\"原始特征数量: {len(data.columns)}\")\n",
    "\n",
    "        # 1. 移除低方差特征\n",
    "        variances = self.calculate_feature_variance(data.drop(target_col, axis=1))\n",
    "        high_variance_features = variances[variances > self.variance_threshold].index.tolist()\n",
    "        print(f\"高方差特征数量: {len(high_variance_features)}\")\n",
    "\n",
    "        # 2. 计算与目标的相关性\n",
    "        correlations = self.calculate_target_correlation(data[high_variance_features + [target_col]], target_col)\n",
    "\n",
    "        # 3. 计算互信息（选择性进行，因为计算成本较高）\n",
    "        mi_scores = {}\n",
    "        if len(high_variance_features) > 1000:\n",
    "            print(\"计算互信息...\")\n",
    "            mi_scores = self.calculate_mutual_information(data[high_variance_features + [target_col]], target_col)\n",
    "\n",
    "        # 4. 综合评分\n",
    "        feature_scores = {}\n",
    "        for feature in high_variance_features:\n",
    "            corr_score = correlations.get(feature, 0)\n",
    "            mi_score = mi_scores.get(feature, 0)\n",
    "\n",
    "            # 综合评分：相关性权重0.7，互信息权重0.3\n",
    "            combined_score = 0.7 * corr_score + 0.3 * mi_score\n",
    "            feature_scores[feature] = combined_score\n",
    "\n",
    "        # 5. 选择Top K特征\n",
    "        sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        selected_features = [feature for feature, score in sorted_features[:self.max_features]]\n",
    "\n",
    "        # 确保目标变量在最终数据中\n",
    "        final_features = selected_features + [target_col]\n",
    "\n",
    "        print(f\"静态特征选择完成，选择 {len(selected_features)} 个特征\")\n",
    "        print(f\"Top 10 特征: {selected_features[:10]}\")\n",
    "\n",
    "        self.selected_features = selected_features\n",
    "        return data[final_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f17e17-8258-4f55-b8e2-efdfe0ecb5ab",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c38989-262e-4be0-80b8-2c0571cd3963",
   "metadata": {
    "id": "40c38989-262e-4be0-80b8-2c0571cd3963"
   },
   "outputs": [],
   "source": [
    "class FeatureProcessor:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def create_lag_features(self, data, lags=[1, 7, 21]):\n",
    "        lagged_data = data.copy()\n",
    "\n",
    "        # 排除目标变量\n",
    "        original_columns = [col for col in data.columns if col != 'ret_21D']\n",
    "        lag_features_created = 0\n",
    "\n",
    "        for lag in lags:\n",
    "            for column in original_columns:\n",
    "                new_col_name = f'{column}_lag_{lag}'\n",
    "                lagged_data[new_col_name] = data[column].shift(lag)\n",
    "                lag_features_created += 1\n",
    "\n",
    "        print(f\"滞后特征处理后数据形状: {lagged_data.shape}\")\n",
    "        return lagged_data\n",
    "\n",
    "    def calculate_rolling_features(self, data, windows=[7, 21, 63]):\n",
    "        \"\"\"计算滚动统计特征\"\"\"\n",
    "        print(\"计算滚动特征...\")\n",
    "        rolled_data = data.copy()\n",
    "\n",
    "        # 排除目标变量\n",
    "        original_columns = [col for col in data.columns if col != 'ret_21D']\n",
    "        roll_features_created = 0\n",
    "\n",
    "        for window in windows:\n",
    "            for column in original_columns:\n",
    "                # 滚动均值\n",
    "                rolled_data[f'{column}_roll_mean_{window}'] = data[column].rolling(window, min_periods=1).mean()\n",
    "                # 滚动标准差\n",
    "                rolled_data[f'{column}_roll_std_{window}'] = data[column].rolling(window, min_periods=1).std()\n",
    "                roll_features_created += 2\n",
    "\n",
    "        print(f\"创建了 {roll_features_created} 个滚动特征\")\n",
    "        print(f\"滚动特征处理后数据形状: {rolled_data.shape}\")\n",
    "        return rolled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bed80f-1488-4951-a78f-8428b3a740b7",
   "metadata": {
    "id": "a4bed80f-1488-4951-a78f-8428b3a740b7"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e295af78-cc65-41a7-9cef-28d7d00fc44b",
   "metadata": {
    "id": "e295af78-cc65-41a7-9cef-28d7d00fc44b"
   },
   "outputs": [],
   "source": [
    "def run_real_data_pipeline():\n",
    "    \"\"\"使用真实数据运行数据处理流程 - 集成特征选择\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"开始真实数据处理流程\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 1. 加载数据\n",
    "    print(\"\\n1. 加载数据...\")\n",
    "    data_folder_path = \"/Users/tuibubansurfacepro/Desktop/flab ai/mnt/nas/yicheng/exercise_flab\"\n",
    "    data_loader = DataLoader(data_folder_path)\n",
    "\n",
    "    try:\n",
    "        main_data = data_loader.load_parquet_files()\n",
    "        print(f\"成功加载数据: {main_data.shape[0]} 行 × {main_data.shape[1]} 列\")\n",
    "        print(f\"时间范围: {main_data.index.min().strftime('%Y-%m-%d')} 至 {main_data.index.max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        # 查找目标变量\n",
    "        target_col = data_loader.find_target_column(main_data)\n",
    "        if target_col:\n",
    "            main_data = main_data.rename(columns={target_col: 'ret_21D'})\n",
    "            target_stats = main_data['ret_21D'].describe()\n",
    "            print(f\"目标变量: 均值={target_stats['mean']:.4f}, 标准差={target_stats['std']:.4f}\")\n",
    "        else:\n",
    "            print(\"警告: 数据中未找到目标变量 'ret_21D'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"数据加载失败: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # 2. 添加宏观数据\n",
    "    print(\"\\n2. 添加宏观数据...\")\n",
    "    try:\n",
    "        macro_enhancer = MacroDataEnhancer()\n",
    "        start_date = main_data.index.min().strftime('%Y-%m-%d')\n",
    "        end_date = main_data.index.max().strftime('%Y-%m-%d')\n",
    "        enhanced_data = macro_enhancer.add_all_macro_data(main_data, start_date, end_date)\n",
    "        print(f\"成功添加 {len(macro_enhancer.macro_features)} 个宏观特征\")\n",
    "    except Exception as e:\n",
    "        print(f\"宏观数据添加失败: {e}\")\n",
    "        enhanced_data = main_data.copy()\n",
    "\n",
    "    # 3. 数据清洗\n",
    "    print(\"\\n3. 数据清洗...\")\n",
    "    try:\n",
    "        cleaner = DataCleaner(nan_threshold=0.8)\n",
    "        cleaned_data = cleaner.clean_data(enhanced_data)\n",
    "        print(f\"清洗完成: 保留 {len(cleaner.kept_features)} 个特征\")\n",
    "    except Exception as e:\n",
    "        print(f\"数据清洗失败: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # 4. 静态特征选择\n",
    "    print(\"\\n4. 特征选择...\")\n",
    "    try:\n",
    "        feature_selector = FeatureSelector(max_features=1000)\n",
    "        selected_data = feature_selector.select_features_static(cleaned_data)\n",
    "        print(f\"特征选择完成: 从 {len(cleaned_data.columns)} 个特征中选择 {len(feature_selector.selected_features)} 个\")\n",
    "    except Exception as e:\n",
    "        print(f\"特征选择失败: {e}\")\n",
    "        selected_data = cleaned_data\n",
    "\n",
    "    # 5. 特征工程\n",
    "    print(\"\\n5. 特征工程...\")\n",
    "    try:\n",
    "        processor = FeatureProcessor()\n",
    "\n",
    "        # 创建滞后特征\n",
    "        data_with_lags = processor.create_lag_features(selected_data, lags=[1, 5, 21])\n",
    "\n",
    "        # 创建滚动特征\n",
    "        data_with_features = processor.calculate_rolling_features(data_with_lags, windows=[5, 21, 63])\n",
    "\n",
    "        print(f\"特征工程完成\")\n",
    "        print(f\"最终数据维度: {data_with_features.shape[0]} 样本 × {data_with_features.shape[1]} 特征\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"特征工程失败: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✅ 数据处理流程完成!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return cleaned_data, data_with_features, processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c59a35-5079-40e2-842a-d378e80d809d",
   "metadata": {
    "id": "a1c59a35-5079-40e2-842a-d378e80d809d",
    "outputId": "82374c17-a58c-4ec3-caa4-7601b5f11e5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 运行真实数据处理流程\\nif __name__ == \"__main__\":\\n    data_folder_path = \"/Users/tuibubansurfacepro/Desktop/flab ai/mnt/nas/yicheng/exercise_flab\"\\n\\n    print(f\"使用数据路径: {data_folder_path}\")\\n\\n    cleaned_data, processed_data, feature_processor = run_real_data_pipeline()\\n\\n    if processed_data is not None:\\n        print(\"\\n数据处理结果摘要:\")\\n        print(f\"- 清洗后数据形状: {cleaned_data.shape if cleaned_data is not None else \\'N/A\\'}\")\\n        print(f\"- 特征工程后数据形状: {processed_data.shape}\")\\n        print(f\"- 特征数量: {len(processed_data.columns)}\")\\n        print(f\"- 数据时间范围: {processed_data.index.min()} 到 {processed_data.index.max()}\")\\n\\n        # 检查目标变量\\n        if \\'ret_21D\\' in processed_data.columns:\\n            target_data = processed_data[\\'ret_21D\\'].dropna()\\n            print(f\"- 目标变量有效样本数: {len(target_data)}\")\\n            print(f\"- 目标变量统计: 均值={target_data.mean():.6f}, 标准差={target_data.std():.6f}\")\\n\\n        # 保存处理后的数据（可选）\\n        save_option = input(\"\\n是否保存处理后的数据? (y/n): \").lower()\\n        if save_option == \\'y\\':\\n            output_path = \"./processed_data.parquet\"\\n            processed_data.to_parquet(output_path)\\n            print(f\"数据已保存至: {output_path}\")\\n    else:\\n        print(\"\\n数据处理失败，请检查错误信息。\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 运行真实数据处理流程\n",
    "if __name__ == \"__main__\":\n",
    "    data_folder_path = \"./flab ai/mnt/nas/yicheng/exercise_flab\"\n",
    "\n",
    "    print(f\"使用数据路径: {data_folder_path}\")\n",
    "\n",
    "    cleaned_data, processed_data, feature_processor = run_real_data_pipeline()\n",
    "\n",
    "    if processed_data is not None:\n",
    "        print(\"\\n数据处理结果摘要:\")\n",
    "        print(f\"- 清洗后数据形状: {cleaned_data.shape if cleaned_data is not None else 'N/A'}\")\n",
    "        print(f\"- 特征工程后数据形状: {processed_data.shape}\")\n",
    "        print(f\"- 特征数量: {len(processed_data.columns)}\")\n",
    "        print(f\"- 数据时间范围: {processed_data.index.min()} 到 {processed_data.index.max()}\")\n",
    "\n",
    "        # 检查目标变量\n",
    "        if 'ret_21D' in processed_data.columns:\n",
    "            target_data = processed_data['ret_21D'].dropna()\n",
    "            print(f\"- 目标变量有效样本数: {len(target_data)}\")\n",
    "            print(f\"- 目标变量统计: 均值={target_data.mean():.6f}, 标准差={target_data.std():.6f}\")\n",
    "\n",
    "        # 保存处理后的数据（可选）\n",
    "        save_option = input(\"\\n是否保存处理后的数据? (y/n): \").lower()\n",
    "        if save_option == 'y':\n",
    "            output_path = \"./processed_data.parquet\"\n",
    "            processed_data.to_parquet(output_path)\n",
    "            print(f\"数据已保存至: {output_path}\")\n",
    "    else:\n",
    "        print(\"\\n数据处理失败，请检查错误信息。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a55f40-927b-486b-85c2-0f85b1f0fd3d",
   "metadata": {
    "id": "30a55f40-927b-486b-85c2-0f85b1f0fd3d"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d82e02e4-d4aa-4d2c-921a-9d6c3ccc1a65",
   "metadata": {
    "id": "d82e02e4-d4aa-4d2c-921a-9d6c3ccc1a65"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aafe37e-811d-4523-941c-3a942f8e50b9",
   "metadata": {},
   "source": [
    "## 动态特征筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd0ded9-2ffd-4dbe-8c0b-0673b2b316f8",
   "metadata": {
    "id": "bdd0ded9-2ffd-4dbe-8c0b-0673b2b316f8"
   },
   "outputs": [],
   "source": [
    "class DynamicFeatureOptimizer:\n",
    "    \"\"\"动态特征优化器 - 在在线学习过程中优化特征集\"\"\"\n",
    "\n",
    "    def __init__(self, initial_features, max_features=500,\n",
    "                 importance_threshold=0.001, stability_window=5):\n",
    "        self.initial_features = initial_features\n",
    "        self.max_features = max_features\n",
    "        self.importance_threshold = importance_threshold\n",
    "        self.stability_window = stability_window\n",
    "\n",
    "        self.feature_importance_history = []\n",
    "        self.current_feature_set = set(initial_features)\n",
    "        self.feature_stability_count = {}\n",
    "\n",
    "    def update_feature_set(self, feature_importance_df, current_date):\n",
    "        \"\"\"基于特征重要性更新特征集\"\"\"\n",
    "        if feature_importance_df is None or len(feature_importance_df) == 0:\n",
    "            return self.current_feature_set\n",
    "\n",
    "        # 记录特征重要性\n",
    "        self.feature_importance_history.append({\n",
    "            'date': current_date,\n",
    "            'importance': feature_importance_df.set_index('feature')['importance'].to_dict()\n",
    "        })\n",
    "\n",
    "        # 计算特征稳定性\n",
    "        for feature in feature_importance_df['feature']:\n",
    "            if feature in self.feature_stability_count:\n",
    "                self.feature_stability_count[feature] += 1\n",
    "            else:\n",
    "                self.feature_stability_count[feature] = 1\n",
    "\n",
    "        # 选择重要且稳定的特征\n",
    "        recent_importance = feature_importance_df.set_index('feature')['importance']\n",
    "        # 过滤低重要性特征\n",
    "        important_features = recent_importance[recent_importance > self.importance_threshold].index.tolist()\n",
    "\n",
    "        # 优先选择稳定性高的特征\n",
    "        feature_stability = pd.Series(self.feature_stability_count)\n",
    "        stable_features = feature_stability[feature_stability >= self.stability_window].index.tolist()\n",
    "\n",
    "        # 合并重要且稳定的特征\n",
    "        candidate_features = set(important_features) & set(stable_features)\n",
    "\n",
    "        # 如果候选特征太少，补充一些重要性高的特征\n",
    "        if len(candidate_features) < self.max_features // 2:\n",
    "            top_features = recent_importance.nlargest(self.max_features).index.tolist()\n",
    "            candidate_features.update(top_features[:self.max_features // 2])\n",
    "\n",
    "        # 限制特征数量\n",
    "        if len(candidate_features) > self.max_features:\n",
    "            # 按重要性排序并选择Top K\n",
    "            candidate_importance = recent_importance.reindex(list(candidate_features)).fillna(0)\n",
    "            top_candidates = candidate_importance.nlargest(self.max_features).index.tolist()\n",
    "            self.current_feature_set = set(top_candidates)\n",
    "        else:\n",
    "            self.current_feature_set = candidate_features\n",
    "\n",
    "        print(f\"动态特征优化: 从 {len(feature_importance_df)} 个特征中选择 {len(self.current_feature_set)} 个特征\")\n",
    "\n",
    "        return self.current_feature_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b3ddf-f750-4a24-9d07-465ab43413fe",
   "metadata": {},
   "source": [
    "# 模型搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1542fee0-9f0e-40b0-98e6-b27feb71fe07",
   "metadata": {},
   "source": [
    "## 树模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf3b06d-c477-473e-a216-927e661a39a7",
   "metadata": {
    "id": "faf3b06d-c477-473e-a216-927e661a39a7"
   },
   "outputs": [],
   "source": [
    "class OnlineTreeModel:\n",
    "    \"\"\"在线学习树模型 - 集成特征优化\"\"\"\n",
    "\n",
    "    def __init__(self, model_type='xgboost', model_params=None,\n",
    "                 train_window=756, retrain_freq=42, prediction_horizon=21,\n",
    "                 normalization_window=252, dynamic_feature_selection=True,\n",
    "                 max_features=200):\n",
    "        \"\"\"\n",
    "        初始化在线学习模型\n",
    "\n",
    "        参数:\n",
    "        - model_type: 模型类型\n",
    "        - model_params: 模型参数\n",
    "        - train_window: 训练窗口大小\n",
    "        - retrain_freq: 重新训练频率\n",
    "        - prediction_horizon: 预测horizon\n",
    "        - normalization_window: 标准化窗口\n",
    "        - dynamic_feature_selection: 是否启用动态特征选择\n",
    "        - max_features: 最大特征数量\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        self.model_params = model_params or {}\n",
    "        self.train_window = train_window\n",
    "        self.retrain_freq = retrain_freq\n",
    "        self.prediction_horizon = prediction_horizon\n",
    "        self.normalization_window = normalization_window\n",
    "        self.dynamic_feature_selection = dynamic_feature_selection\n",
    "        self.max_features = max_features\n",
    "\n",
    "        self.model = None\n",
    "        self.feature_importance_history = []\n",
    "        self.prediction_history = []\n",
    "        self.normalization_params = {}\n",
    "        self.normalization_history = {}\n",
    "        self.feature_optimizer = None\n",
    "        self.current_feature_set = None\n",
    "\n",
    "        # 设置默认模型参数\n",
    "        if not self.model_params:\n",
    "            if model_type == 'xgboost':\n",
    "                self.model_params = {\n",
    "                    'n_estimators': 50,\n",
    "                    'max_depth': 6,\n",
    "                    'learning_rate': 0.05,\n",
    "                    'subsample': 0.7,\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'random_state': 42,\n",
    "                    'n_jobs': -1\n",
    "                }\n",
    "\n",
    "    def initialize_model(self):\n",
    "        \"\"\"初始化模型\"\"\"\n",
    "        if self.model_type == 'xgboost':\n",
    "            import xgboost as xgb\n",
    "            self.model = xgb.XGBRegressor(**self.model_params)\n",
    "        elif self.model_type == 'random_forest':\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "            self.model = RandomForestRegressor(**self.model_params)\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的模型类型: {self.model_type}\")\n",
    "\n",
    "    def calculate_mad(self, series):\n",
    "        \"\"\"计算平均绝对偏差 (MAD) - 替代已弃用的 .mad() 方法\"\"\"\n",
    "        if len(series) == 0:\n",
    "            return 0\n",
    "        median = series.median()\n",
    "        return (series - median).abs().mean()\n",
    "\n",
    "    def calculate_normalization_params(self, data, current_date):\n",
    "        \"\"\"计算标准化参数 - 使用滑动窗口\"\"\"\n",
    "        # 获取当前日期之前的标准化窗口数据\n",
    "        historical_data = data[data.index <= current_date]\n",
    "        if len(historical_data) < self.normalization_window:\n",
    "            window_data = historical_data\n",
    "        else:\n",
    "            window_data = historical_data.tail(self.normalization_window)\n",
    "\n",
    "        normalization_params = {}\n",
    "\n",
    "        for column in data.columns:\n",
    "            if column != 'ret_21D':\n",
    "                window_values = window_data[column].dropna()\n",
    "\n",
    "                if len(window_values) < 10:\n",
    "                    continue\n",
    "\n",
    "                mean_val = window_values.mean()\n",
    "                std_val = window_values.std()\n",
    "\n",
    "                if std_val < 1e-10:\n",
    "                    median_val = window_values.median()\n",
    "                    normalization_params[column] = {\n",
    "                        'mean': median_val,\n",
    "                        'std': 1.0,\n",
    "                        'method': 'median_centering'\n",
    "                    }\n",
    "                else:\n",
    "                    # 使用自定义的MAD计算方法\n",
    "                    mad_val = self.calculate_mad(window_values)\n",
    "\n",
    "                    # 检查异常大的标准差（可能由于异常值）\n",
    "                    if std_val > 10 * mad_val:  # 用MAD检测异常\n",
    "                        # 使用更稳健的标准化\n",
    "                        median_val = window_values.median()\n",
    "                        normalization_params[column] = {\n",
    "                            'mean': median_val,\n",
    "                            'std': mad_val if mad_val > 1e-10 else 1.0,\n",
    "                            'method': 'robust_normalization'\n",
    "                        }\n",
    "                    else:\n",
    "                        # 正常标准化\n",
    "                        normalization_params[column] = {\n",
    "                            'mean': mean_val,\n",
    "                            'std': std_val,\n",
    "                            'method': 'standard_normalization'\n",
    "                        }\n",
    "\n",
    "                if column not in self.normalization_history:\n",
    "                    self.normalization_history[column] = []\n",
    "\n",
    "                self.normalization_history[column].append({\n",
    "                    'date': current_date,\n",
    "                    'mean': normalization_params[column]['mean'],\n",
    "                    'std': normalization_params[column]['std'],\n",
    "                    'method': normalization_params[column]['method']\n",
    "                })\n",
    "\n",
    "        return normalization_params\n",
    "\n",
    "    def apply_normalization(self, data, normalization_params):\n",
    "        \"\"\"应用标准化\"\"\"\n",
    "        normalized_data = data.copy()\n",
    "\n",
    "        for column, params in normalization_params.items():\n",
    "            if column in normalized_data.columns:\n",
    "                mean_val = params['mean']\n",
    "                std_val = params['std']\n",
    "\n",
    "                if std_val > 1e-10:\n",
    "                    normalized_data[column] = (data[column] - mean_val) / std_val\n",
    "                else:\n",
    "                    normalized_data[column] = data[column] - mean_val\n",
    "\n",
    "        return normalized_data\n",
    "\n",
    "    def prepare_training_data(self, data, current_date, initial_training=False):\n",
    "        \"\"\"准备训练数据 - 集成特征选择\"\"\"\n",
    "        # 获取当前日期之前的数据\n",
    "        historical_data = data[data.index <= current_date]\n",
    "\n",
    "        if len(historical_data) < self.train_window:\n",
    "            train_data = historical_data\n",
    "        else:\n",
    "            train_data = historical_data.tail(self.train_window)\n",
    "\n",
    "        # 移除目标变量为NaN的样本\n",
    "        train_data = train_data.dropna(subset=['ret_21D'])\n",
    "\n",
    "        if len(train_data) < 100:\n",
    "            return None, None, None\n",
    "\n",
    "        # 分离特征和目标\n",
    "        X = train_data.drop('ret_21D', axis=1)\n",
    "        y = train_data['ret_21D']\n",
    "\n",
    "        # 初始训练或首次训练时初始化特征优化器\n",
    "        if initial_training or self.feature_optimizer is None:\n",
    "            if self.dynamic_feature_selection:\n",
    "                self.feature_optimizer = DynamicFeatureOptimizer(\n",
    "                    initial_features=X.columns.tolist(),\n",
    "                    max_features=self.max_features\n",
    "                )\n",
    "                self.current_feature_set = set(X.columns.tolist())\n",
    "\n",
    "        # 动态特征选择\n",
    "        if self.dynamic_feature_selection and self.feature_optimizer and not initial_training:\n",
    "            # 使用当前特征集\n",
    "            available_features = set(X.columns) & self.current_feature_set\n",
    "            if available_features:\n",
    "                X = X[list(available_features)]\n",
    "\n",
    "        # 移除在训练集中全为NaN的列\n",
    "        X = X.dropna(axis=1, how='all')\n",
    "\n",
    "        # 移除常数特征\n",
    "        constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "        X = X.drop(columns=constant_cols)\n",
    "\n",
    "        if len(X.columns) == 0:\n",
    "            return None, None, None\n",
    "\n",
    "        # 计算标准化参数\n",
    "        self.normalization_params = self.calculate_normalization_params(X, current_date)\n",
    "\n",
    "        # 应用标准化\n",
    "        X_normalized = self.apply_normalization(X, self.normalization_params)\n",
    "\n",
    "        # 前向填充剩余的NaN\n",
    "        X_normalized = X_normalized.ffill().bfill().fillna(0)\n",
    "\n",
    "        return X_normalized, y, X_normalized.columns.tolist()\n",
    "\n",
    "    def train_model(self, data, current_date, initial_training=False):\n",
    "        \"\"\"训练模型 - 集成动态特征优化\"\"\"\n",
    "        X, y, feature_names = self.prepare_training_data(data, current_date, initial_training)\n",
    "\n",
    "        if X is None or len(X) == 0:\n",
    "            if OutputConfig.SHOW_TRAINING_DETAILS:\n",
    "                print(f\"在 {current_date.strftime('%Y-%m-%d')} 训练数据不足，跳过训练\")\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            if self.model is None:\n",
    "                self.initialize_model()\n",
    "\n",
    "            self.model.fit(X, y)\n",
    "\n",
    "            # 记录特征重要性\n",
    "            if hasattr(self.model, 'feature_importances_'):\n",
    "                importance_df = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': self.model.feature_importances_,\n",
    "                    'date': current_date\n",
    "                }).sort_values('importance', ascending=False)\n",
    "\n",
    "                self.feature_importance_history.append(importance_df)\n",
    "\n",
    "                # 动态特征优化\n",
    "                if self.dynamic_feature_selection and self.feature_optimizer and not initial_training:\n",
    "                    self.current_feature_set = self.feature_optimizer.update_feature_set(\n",
    "                        importance_df, current_date\n",
    "                    )\n",
    "\n",
    "            if initial_training or OutputConfig.SHOW_TRAINING_DETAILS:\n",
    "                print(f\"{current_date.strftime('%Y-%m-%d')}: 训练完成 - {len(X)} 样本, {len(feature_names)} 特征\")\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            if OutputConfig.SHOW_TRAINING_DETAILS:\n",
    "                print(f\"{current_date.strftime('%Y-%m-%d')}: 训练失败 - {e}\")\n",
    "            return False\n",
    "\n",
    "    def predict(self, data, current_date):\n",
    "        \"\"\"预测当前日期的未来21天收益率\"\"\"\n",
    "        if self.model is None:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # 获取当前日期的特征\n",
    "            current_features = data[data.index == current_date].drop('ret_21D', axis=1)\n",
    "\n",
    "            if len(current_features) == 0:\n",
    "                return None\n",
    "\n",
    "            # 动态特征选择\n",
    "            if self.dynamic_feature_selection and self.current_feature_set:\n",
    "                available_features = set(current_features.columns) & self.current_feature_set\n",
    "                current_features = current_features[list(available_features)]\n",
    "\n",
    "            # 应用相同的标准化\n",
    "            current_features_normalized = self.apply_normalization(current_features, self.normalization_params)\n",
    "\n",
    "            # 确保特征与训练时一致\n",
    "            if hasattr(self.model, 'feature_names_in_'):\n",
    "                expected_features = self.model.feature_names_in_\n",
    "                missing_features = set(expected_features) - set(current_features_normalized.columns)\n",
    "\n",
    "                if missing_features:\n",
    "                    for feature in missing_features:\n",
    "                        current_features_normalized[feature] = 0\n",
    "\n",
    "                current_features_normalized = current_features_normalized[expected_features]\n",
    "\n",
    "            # 处理NaN值\n",
    "            current_features_normalized = current_features_normalized.ffill().bfill().fillna(0)\n",
    "\n",
    "            prediction = self.model.predict(current_features_normalized)[0]\n",
    "\n",
    "            # 记录预测\n",
    "            actual_return = None\n",
    "            if 'ret_21D' in data.columns:\n",
    "                actual_data = data.loc[data.index == current_date, 'ret_21D']\n",
    "                if len(actual_data) > 0:\n",
    "                    actual_return = actual_data.iloc[0]\n",
    "\n",
    "            self.prediction_history.append({\n",
    "                'date': current_date,\n",
    "                'prediction': prediction,\n",
    "                'actual': actual_return\n",
    "            })\n",
    "\n",
    "            return prediction\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"在 {current_date} 预测失败: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f8f197-a4b1-455c-ba07-2099afcbc507",
   "metadata": {},
   "source": [
    "## 信号搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "861e1c8f-f295-481a-b771-8a2a4d8c3843",
   "metadata": {
    "id": "qIHUpKYj67DM"
   },
   "outputs": [],
   "source": [
    "class AdvancedPortfolioManager:\n",
    "\n",
    "    def __init__(self, initial_capital=1000000, max_position=0.02,\n",
    "                 transaction_cost=0.005, volatility_lookback=126,\n",
    "                 kelly_fraction=0.08, min_volatility=0.03,\n",
    "                 prediction_threshold=0.01):\n",
    "        \"\"\"\n",
    "        统一的投资组合管理器 - 保守参数\n",
    "        \"\"\"\n",
    "        self.initial_capital = initial_capital\n",
    "        self.current_capital = initial_capital\n",
    "        self.max_position = max_position\n",
    "        self.transaction_cost = transaction_cost\n",
    "        self.volatility_lookback = volatility_lookback\n",
    "        self.kelly_fraction = kelly_fraction\n",
    "        self.min_volatility = min_volatility\n",
    "        self.prediction_threshold = prediction_threshold\n",
    "\n",
    "        # 投资组合跟踪\n",
    "        self.portfolio_value = [initial_capital]\n",
    "        self.dates = []\n",
    "        self.positions = {}\n",
    "        self.trade_history = []\n",
    "        self.portfolio_weights_history = []\n",
    "\n",
    "        # 性能监控\n",
    "        self.consecutive_losses = 0\n",
    "        self.max_consecutive_losses = 5\n",
    "\n",
    "    def calculate_volatility(self, returns_series, lookback=None):\n",
    "        \"\"\"统一的波动率计算方法\"\"\"\n",
    "        if lookback is None:\n",
    "            lookback = self.volatility_lookback\n",
    "\n",
    "        if len(returns_series) < 30:\n",
    "            return self.min_volatility\n",
    "\n",
    "        available_data = returns_series.tail(min(lookback, len(returns_series))).dropna()\n",
    "\n",
    "        if len(available_data) < 30:\n",
    "            return self.min_volatility\n",
    "\n",
    "        # 使用稳健的波动率估计\n",
    "        median = available_data.median()\n",
    "        mad = (available_data - median).abs().median()\n",
    "        volatility = mad * 1.4826  # 将MAD转换为标准差估计\n",
    "\n",
    "        # 严格的波动率限制\n",
    "        volatility = max(volatility, self.min_volatility)\n",
    "        volatility = min(volatility, 0.30)\n",
    "\n",
    "        return volatility\n",
    "\n",
    "    def conservative_kelly_sizing(self, prediction, volatility, recent_performance=None):\n",
    "        \"\"\"保守的凯利仓位管理\"\"\"\n",
    "        if recent_performance is None:\n",
    "            recent_performance = {'consecutive_losses': 0, 'win_rate': 0.5}\n",
    "\n",
    "        # 更高的预测阈值\n",
    "        if abs(prediction) < self.prediction_threshold:\n",
    "            return 0\n",
    "\n",
    "        # 连续亏损惩罚\n",
    "        performance_penalty = 1.0\n",
    "        if recent_performance.get('consecutive_losses', 0) > 2:\n",
    "            performance_penalty = 0.5\n",
    "        elif recent_performance.get('win_rate', 0.5) < 0.4:\n",
    "            performance_penalty = 0.7\n",
    "\n",
    "        # 基础凯利计算\n",
    "        raw_kelly = prediction / (volatility ** 2)\n",
    "\n",
    "        # 多重保守调整\n",
    "        signal_strength = min(abs(prediction) / 0.08, 1.0)\n",
    "        vol_penalty = 1.0 / (1.0 + 3.0 * volatility)\n",
    "\n",
    "        adjusted_kelly = raw_kelly * signal_strength * vol_penalty * self.kelly_fraction * performance_penalty\n",
    "\n",
    "        # 非常严格的仓位限制\n",
    "        position_size = np.clip(adjusted_kelly, -self.max_position, self.max_position)\n",
    "\n",
    "        # 更高的最小仓位阈值\n",
    "        if abs(position_size) < 0.002:\n",
    "            position_size = 0\n",
    "\n",
    "        return position_size\n",
    "\n",
    "    def get_recent_performance(self):\n",
    "        \"\"\"获取近期表现\"\"\"\n",
    "        if len(self.trade_history) < 10:\n",
    "            return {'consecutive_losses': self.consecutive_losses, 'win_rate': 0.5}\n",
    "\n",
    "        recent_trades = self.trade_history[-10:]\n",
    "        wins = sum(1 for trade in recent_trades if trade.get('portfolio_return', 0) > 0)\n",
    "        win_rate = wins / len(recent_trades)\n",
    "\n",
    "        return {\n",
    "            'consecutive_losses': self.consecutive_losses,\n",
    "            'win_rate': win_rate\n",
    "        }\n",
    "\n",
    "    def execute_advanced_trades(self, date, asset_data, predictions, current_capital):\n",
    "        \"\"\"执行高级交易 - 统一方法名\"\"\"\n",
    "        self.current_capital = current_capital\n",
    "\n",
    "        if not predictions:\n",
    "            self.portfolio_value.append(current_capital)\n",
    "            self.dates.append(date)\n",
    "            return current_capital, 0, {}\n",
    "\n",
    "        asset_name = list(predictions.keys())[0] if predictions else 'primary_asset'\n",
    "        prediction = predictions.get(asset_name, 0)\n",
    "\n",
    "        # 计算近期表现\n",
    "        recent_performance = self.get_recent_performance()\n",
    "\n",
    "        # 波动率计算\n",
    "        volatility = self.min_volatility\n",
    "        if asset_name in asset_data and 'returns' in asset_data[asset_name]:\n",
    "            returns_series = asset_data[asset_name]['returns']\n",
    "            volatility = self.calculate_volatility(returns_series)\n",
    "\n",
    "        # 保守仓位计算\n",
    "        position_size = self.conservative_kelly_sizing(prediction, volatility, recent_performance)\n",
    "\n",
    "        if position_size == 0:\n",
    "            self.portfolio_value.append(current_capital)\n",
    "            self.dates.append(date)\n",
    "            return current_capital, 0, {}\n",
    "\n",
    "        # 交易成本\n",
    "        transaction_cost = abs(position_size) * self.transaction_cost\n",
    "\n",
    "        # 收益计算 - 使用更保守的方法\n",
    "        portfolio_return = 0\n",
    "        if asset_name in asset_data and 'returns' in asset_data[asset_name]:\n",
    "            returns_series = asset_data[asset_name]['returns']\n",
    "            if len(returns_series) > 0:\n",
    "                # 使用最近5天的平均收益率\n",
    "                recent_returns = returns_series.tail(5)\n",
    "                asset_return = recent_returns.mean() if len(recent_returns) > 0 else 0\n",
    "                portfolio_return = position_size * asset_return\n",
    "\n",
    "        # 扣除交易成本\n",
    "        portfolio_return -= transaction_cost\n",
    "\n",
    "        # 更新资金\n",
    "        new_capital = current_capital * (1 + portfolio_return)\n",
    "        self.current_capital = new_capital\n",
    "\n",
    "        # 记录交易\n",
    "        weights = {asset_name: position_size}\n",
    "        trade_record = {\n",
    "            'date': date,\n",
    "            'weights': weights,\n",
    "            'portfolio_return': portfolio_return,\n",
    "            'transaction_cost': transaction_cost,\n",
    "            'capital_before': current_capital,\n",
    "            'capital_after': new_capital,\n",
    "            'prediction': prediction\n",
    "        }\n",
    "        self.trade_history.append(trade_record)\n",
    "        self.portfolio_value.append(new_capital)\n",
    "        self.dates.append(date)\n",
    "        self.portfolio_weights_history.append(trade_record)\n",
    "\n",
    "        # 更新连续亏损计数\n",
    "        if portfolio_return < 0:\n",
    "            self.consecutive_losses += 1\n",
    "        else:\n",
    "            self.consecutive_losses = 0\n",
    "\n",
    "        # 如果连续亏损过多，输出警告\n",
    "        if self.consecutive_losses >= self.max_consecutive_losses:\n",
    "            print(f\"警告: 连续{self.consecutive_losses}次亏损\")\n",
    "\n",
    "        return new_capital, portfolio_return, weights\n",
    "\n",
    "    def get_performance_summary(self):\n",
    "        \"\"\"获取投资组合绩效摘要\"\"\"\n",
    "        if len(self.portfolio_value) < 2:\n",
    "            return {}\n",
    "\n",
    "        portfolio_returns = pd.Series(self.portfolio_value).pct_change().dropna()\n",
    "\n",
    "        total_return = (self.portfolio_value[-1] / self.portfolio_value[0] - 1) * 100\n",
    "        annual_return = portfolio_returns.mean() * 252 * 100\n",
    "        annual_volatility = portfolio_returns.std() * np.sqrt(252) * 100\n",
    "        sharpe_ratio = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
    "\n",
    "        # 计算最大回撤\n",
    "        portfolio_series = pd.Series(self.portfolio_value)\n",
    "        rolling_max = portfolio_series.expanding().max()\n",
    "        drawdowns = (portfolio_series - rolling_max) / rolling_max\n",
    "        max_drawdown = drawdowns.min() * 100\n",
    "\n",
    "        # 计算胜率\n",
    "        winning_periods = len([r for r in portfolio_returns if r > 0])\n",
    "        win_rate = winning_periods / len(portfolio_returns) * 100 if len(portfolio_returns) > 0 else 0\n",
    "\n",
    "        return {\n",
    "            'Total Return (%)': total_return,\n",
    "            'Annual Return (%)': annual_return,\n",
    "            'Annual Volatility (%)': annual_volatility,\n",
    "            'Sharpe Ratio': sharpe_ratio,\n",
    "            'Max Drawdown (%)': max_drawdown,\n",
    "            'Win Rate (%)': win_rate,\n",
    "            'Final Capital': self.portfolio_value[-1],\n",
    "            'Number of Trades': len(self.trade_history)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f961127-d98b-4845-b618-c11c363b163f",
   "metadata": {},
   "source": [
    "# 回测流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bddf3196-d35e-4db0-985c-e85ad1098bee",
   "metadata": {
    "id": "bddf3196-d35e-4db0-985c-e85ad1098bee"
   },
   "outputs": [],
   "source": [
    "class EnhancedStrategyBacktester:\n",
    "\n",
    "    def __init__(self, model, portfolio_manager):\n",
    "        self.model = model\n",
    "        self.portfolio_manager = portfolio_manager\n",
    "        self.performance_metrics = {}\n",
    "\n",
    "    def run_enhanced_backtest(self, data, start_date, end_date):\n",
    "        \"\"\"运行增强回测\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"开始策略回测\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # 筛选回测期间的数据\n",
    "        backtest_data = data[(data.index >= start_date) & (data.index <= end_date)]\n",
    "\n",
    "        # 确保dates变量被正确赋值\n",
    "        if backtest_data.empty:\n",
    "            print(\"警告: 回测期间没有数据!\")\n",
    "            return {\n",
    "                'portfolio_values': [self.portfolio_manager.initial_capital],\n",
    "                'portfolio_dates': [start_date],\n",
    "                'weights_history': [],\n",
    "                'predictions': [],\n",
    "                'actual_returns': [],\n",
    "                'signal_dates': [],\n",
    "                'metrics': {},\n",
    "                'feature_importance': self.model.feature_importance_history\n",
    "            }\n",
    "\n",
    "        dates = backtest_data.index.unique()\n",
    "        dates = sorted(dates)\n",
    "\n",
    "        capital = self.portfolio_manager.initial_capital\n",
    "        portfolio_values = [capital]\n",
    "        portfolio_dates = [dates[0] if len(dates) > 0 else start_date]\n",
    "        portfolio_weights_history = []\n",
    "        predictions_list = []\n",
    "        actual_returns_list = []\n",
    "        signal_dates = []\n",
    "\n",
    "        print(f\"回测期间: {start_date.strftime('%Y-%m-%d')} 至 {end_date.strftime('%Y-%m-%d')}\")\n",
    "        print(f\"总交易日: {len(dates)}\")\n",
    "\n",
    "        for i, current_date in enumerate(dates):\n",
    "            # 显示进度\n",
    "            if OutputConfig.SHOW_PROGRESS and i % max(1, len(dates) // 20) == 0:\n",
    "                progress = (i + 1) / len(dates) * 100\n",
    "                print(f\"进度: {i+1}/{len(dates)} ({progress:.1f}%)\")\n",
    "\n",
    "            # 定期重新训练模型\n",
    "            if i % self.model.retrain_freq == 0:\n",
    "                if OutputConfig.SHOW_TRAINING_DETAILS:\n",
    "                    print(f\"{current_date.strftime('%Y-%m-%d')}: 重新训练模型...\")\n",
    "                success = self.model.train_model(data, current_date)\n",
    "                if not success and i > 0 and OutputConfig.SHOW_TRAINING_DETAILS:\n",
    "                    print(\"训练失败，使用之前的模型继续预测\")\n",
    "\n",
    "            # 进行预测\n",
    "            prediction = self.model.predict(data, current_date)  # 使用完整data而不是backtest_data\n",
    "\n",
    "            if prediction is not None:\n",
    "                # 添加预测值调试\n",
    "                if OutputConfig.VERBOSE:\n",
    "                    print(f\"{current_date.strftime('%Y-%m-%d')}: 预测值 = {prediction:.6f}\")\n",
    "\n",
    "                predictions_list.append(prediction)\n",
    "                signal_dates.append(current_date)\n",
    "\n",
    "                # 获取实际收益率\n",
    "                actual_return_data = data.loc[data.index == current_date, 'ret_21D']\n",
    "                if len(actual_return_data) > 0:\n",
    "                    actual_return = actual_return_data.iloc[0]\n",
    "                    actual_returns_list.append(actual_return)\n",
    "                else:\n",
    "                    actual_returns_list.append(0)\n",
    "\n",
    "                # 构建资产数据\n",
    "                asset_data = self.prepare_asset_data(data, current_date)\n",
    "\n",
    "                # 执行高级交易\n",
    "                try:\n",
    "                    capital, portfolio_return, weights = self.portfolio_manager.execute_advanced_trades(\n",
    "                        current_date, asset_data, {'primary_asset': prediction}, capital\n",
    "                    )\n",
    "\n",
    "                    # 记录交易结果\n",
    "                    portfolio_values.append(capital)\n",
    "                    portfolio_dates.append(current_date)\n",
    "                    portfolio_weights_history.append({\n",
    "                        'date': current_date,\n",
    "                        'weights': weights,\n",
    "                        'portfolio_return': portfolio_return,\n",
    "                        'prediction': prediction,\n",
    "                        'actual_return': actual_returns_list[-1] if actual_returns_list else None\n",
    "                    })\n",
    "\n",
    "                    # 显示交易结果（如果交易成功）\n",
    "                    if weights and any(w != 0 for w in weights.values()):\n",
    "                        if OutputConfig.VERBOSE:\n",
    "                            print(f\"{current_date.strftime('%Y-%m-%d')}: 仓位 = {weights}, 收益 = {portfolio_return:.4f}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  {current_date.strftime('%Y-%m-%d')}: 交易执行失败 - {e}\")\n",
    "                    # 即使交易失败，也记录投资组合价值\n",
    "                    portfolio_values.append(capital)\n",
    "                    portfolio_dates.append(current_date)\n",
    "\n",
    "        # 计算绩效指标\n",
    "        self.performance_metrics = self.calculate_enhanced_metrics(\n",
    "            portfolio_values, portfolio_weights_history, predictions_list, actual_returns_list\n",
    "        )\n",
    "\n",
    "        print(f\"回测完成: {len(predictions_list)} 次预测, {len(portfolio_weights_history)} 次交易\")\n",
    "\n",
    "        return {\n",
    "            'portfolio_values': portfolio_values,\n",
    "            'portfolio_dates': portfolio_dates,\n",
    "            'weights_history': portfolio_weights_history,\n",
    "            'predictions': predictions_list,\n",
    "            'actual_returns': actual_returns_list,\n",
    "            'signal_dates': signal_dates,\n",
    "            'metrics': self.performance_metrics,\n",
    "            'feature_importance': self.model.feature_importance_history\n",
    "        }\n",
    "\n",
    "\n",
    "    def prepare_asset_data(self, data, current_date):\n",
    "        \"\"\"准备资产数据 - 为单一资产情况设计\"\"\"\n",
    "        # 获取历史数据用于计算波动率等指标\n",
    "        historical_data = data[data.index <= current_date]\n",
    "\n",
    "        # 假设只有一个主要资产\n",
    "        asset_data = {\n",
    "            'primary_asset': {\n",
    "                'returns': historical_data['ret_21D'],\n",
    "                # 如果没有价格数据，用累积收益率模拟价格序列\n",
    "                'prices': self.calculate_price_series(historical_data['ret_21D']),\n",
    "                'volatility': self.calculate_rolling_volatility(historical_data['ret_21D'])\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return asset_data\n",
    "\n",
    "    def calculate_price_series(self, returns_series, initial_price=100):\n",
    "        \"\"\"根据收益率序列计算价格序列\"\"\"\n",
    "        if len(returns_series) == 0:\n",
    "            return pd.Series([initial_price])\n",
    "\n",
    "        # 计算累积收益率\n",
    "        cumulative_returns = (1 + returns_series).cumprod()\n",
    "\n",
    "        # 转换为价格序列\n",
    "        price_series = initial_price * cumulative_returns\n",
    "\n",
    "        return price_series\n",
    "\n",
    "    def calculate_rolling_volatility(self, returns_series, window=63):\n",
    "        \"\"\"计算滚动波动率\"\"\"\n",
    "        if len(returns_series) < window:\n",
    "            return returns_series.std() if len(returns_series) > 0 else 0.02\n",
    "\n",
    "        return returns_series.rolling(window=window, min_periods=10).std().iloc[-1] if len(returns_series) > 0 else 0.02\n",
    "\n",
    "    def calculate_enhanced_metrics(self, portfolio_values, weights_history, predictions, actual_returns):\n",
    "        \"\"\"计算增强绩效指标\"\"\"\n",
    "        portfolio_returns = pd.Series(portfolio_values).pct_change().dropna()\n",
    "\n",
    "        if len(portfolio_returns) == 0:\n",
    "            return {}\n",
    "\n",
    "        # 基本指标\n",
    "        total_return = (portfolio_values[-1] / portfolio_values[0] - 1) * 100\n",
    "        annual_return = portfolio_returns.mean() * 252 * 100\n",
    "        annual_volatility = portfolio_returns.std() * np.sqrt(252) * 100\n",
    "        sharpe_ratio = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
    "\n",
    "        # 风险调整指标\n",
    "        downside_returns = portfolio_returns[portfolio_returns < 0]\n",
    "        sortino_ratio = annual_return / (downside_returns.std() * np.sqrt(252) * 100) if len(downside_returns) > 0 else 0\n",
    "\n",
    "        # 最大回撤\n",
    "        max_drawdown = self.calculate_max_drawdown(portfolio_values) * 100\n",
    "\n",
    "        # Calmar比率\n",
    "        calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown != 0 else 0\n",
    "\n",
    "        # 胜率\n",
    "        winning_periods = len([r for r in portfolio_returns if r > 0])\n",
    "        win_rate = winning_periods / len(portfolio_returns) if len(portfolio_returns) > 0 else 0\n",
    "\n",
    "        # 预测精度指标\n",
    "        prediction_accuracy = 0\n",
    "        if len(predictions) > 0 and len(actual_returns) > 0:\n",
    "            min_len = min(len(predictions), len(actual_returns))\n",
    "            predictions_arr = np.array(predictions[:min_len])\n",
    "            actual_arr = np.array(actual_returns[:min_len])\n",
    "\n",
    "            # 相关性\n",
    "            if min_len > 1:\n",
    "                correlation_matrix = np.corrcoef(predictions_arr, actual_arr)\n",
    "                correlation = correlation_matrix[0, 1] if not np.isnan(correlation_matrix[0, 1]) else 0\n",
    "            else:\n",
    "                correlation = 0\n",
    "\n",
    "            # 均方误差\n",
    "            mse = mean_squared_error(actual_arr, predictions_arr) if min_len > 0 else 0\n",
    "\n",
    "            # 方向准确性\n",
    "            direction_correct = np.sum(\n",
    "                (predictions_arr > 0) == (actual_arr > 0)\n",
    "            ) / min_len if min_len > 0 else 0\n",
    "\n",
    "            # 信息系数 (IC)\n",
    "            ic = correlation\n",
    "        else:\n",
    "            correlation = 0\n",
    "            mse = 0\n",
    "            direction_correct = 0\n",
    "            ic = 0\n",
    "\n",
    "        # 交易相关指标\n",
    "        total_trades = len(weights_history)\n",
    "        positive_trades = len([w for w in weights_history if w.get('portfolio_return', 0) > 0])\n",
    "        trade_win_rate = positive_trades / total_trades if total_trades > 0 else 0\n",
    "\n",
    "        # 平均持仓比例\n",
    "        avg_position_size = np.mean([sum(w['weights'].values()) for w in weights_history]) if weights_history else 0\n",
    "\n",
    "        metrics = {\n",
    "            # 收益指标\n",
    "            'Total Return (%)': total_return,\n",
    "            'Annual Return (%)': annual_return,\n",
    "            'Annual Volatility (%)': annual_volatility,\n",
    "            'Sharpe Ratio': sharpe_ratio,\n",
    "            'Sortino Ratio': sortino_ratio,\n",
    "            'Calmar Ratio': calmar_ratio,\n",
    "            'Max Drawdown (%)': max_drawdown,\n",
    "            'Win Rate (%)': win_rate,\n",
    "\n",
    "            # 预测精度指标\n",
    "            'Prediction Correlation': correlation,\n",
    "            'Information Coefficient': ic,\n",
    "            'Prediction MSE': mse,\n",
    "            'Direction Accuracy': direction_correct,\n",
    "\n",
    "            # 交易指标\n",
    "            'Number of Trades': total_trades,\n",
    "            'Trade Win Rate (%)': trade_win_rate * 100,\n",
    "            'Average Position Size (%)': avg_position_size * 100,\n",
    "\n",
    "            # 其他\n",
    "            'Final Portfolio Value': portfolio_values[-1],\n",
    "            'Initial Capital': self.portfolio_manager.initial_capital\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def calculate_max_drawdown(self, portfolio_values):\n",
    "        \"\"\"计算最大回撤\"\"\"\n",
    "        portfolio_series = pd.Series(portfolio_values)\n",
    "        rolling_max = portfolio_series.expanding().max()\n",
    "        drawdown = (portfolio_series - rolling_max) / rolling_max\n",
    "        return drawdown.min()\n",
    "\n",
    "    def generate_enhanced_report(self, backtest_results):\n",
    "        \"\"\"生成增强回测报告\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"回测结果报告\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        metrics = backtest_results['metrics']\n",
    "\n",
    "        print(\"\\n核心绩效指标:\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        # 收益指标\n",
    "        print(\"\\n收益表现:\")\n",
    "        print(f\"   总收益率: {metrics.get('Total Return (%)', 0):.2f}%\")\n",
    "        print(f\"   年化收益率: {metrics.get('Annual Return (%)', 0):.2f}%\")\n",
    "        print(f\"   年化波动率: {metrics.get('Annual Volatility (%)', 0):.2f}%\")\n",
    "        print(f\"   夏普比率: {metrics.get('Sharpe Ratio', 0):.4f}\")\n",
    "\n",
    "        # 风险指标\n",
    "        print(\"\\n风险控制:\")\n",
    "        print(f\"   最大回撤: {metrics.get('Max Drawdown (%)', 0):.2f}%\")\n",
    "        print(f\"   索提诺比率: {metrics.get('Sortino Ratio', 0):.4f}\")\n",
    "\n",
    "        # 预测精度\n",
    "        print(\"\\n预测质量:\")\n",
    "        print(f\"   预测相关性: {metrics.get('Prediction Correlation', 0):.4f}\")\n",
    "        print(f\"   方向准确率: {metrics.get('Direction Accuracy', 0):.4f}\")\n",
    "\n",
    "        # 交易统计\n",
    "        print(\"\\n交易统计:\")\n",
    "        print(f\"   交易次数: {metrics.get('Number of Trades', 0)}\")\n",
    "        print(f\"   交易胜率: {metrics.get('Trade Win Rate (%)', 0):.2f}%\")\n",
    "\n",
    "        # 资金信息\n",
    "        print(\"\\n资金信息:\")\n",
    "        print(f\"   初始资本: ${metrics.get('Initial Capital', 0):,.0f}\")\n",
    "        print(f\"   最终价值: ${metrics.get('Final Portfolio Value', 0):,.0f}\")\n",
    "        print(f\"   绝对收益: ${metrics.get('Final Portfolio Value', 0) - metrics.get('Initial Capital', 0):,.0f}\")\n",
    "\n",
    "        # 显示最重要的特征\n",
    "        if backtest_results['feature_importance'] and OutputConfig.SHOW_FEATURE_DETAILS:\n",
    "            latest_importance = backtest_results['feature_importance'][-1]\n",
    "            top_features = latest_importance.head(5)\n",
    "            print(f\"\\nTop 5 重要特征:\")\n",
    "            for i, (_, row) in enumerate(top_features.iterrows(), 1):\n",
    "                print(f\"   {i}. {row['feature'][:50]}...: {row['importance']:.4f}\")\n",
    "\n",
    "\n",
    "    def analyze_prediction_quality(self, backtest_results):\n",
    "        \"\"\"分析预测质量\"\"\"\n",
    "        predictions = backtest_results['predictions']\n",
    "        actual_returns = backtest_results['actual_returns']\n",
    "\n",
    "        if len(predictions) == 0 or len(actual_returns) == 0:\n",
    "            print(\"没有足够的预测数据进行分析\")\n",
    "            return\n",
    "\n",
    "        min_len = min(len(predictions), len(actual_returns))\n",
    "        predictions_arr = np.array(predictions[:min_len])\n",
    "        actual_arr = np.array(actual_returns[:min_len])\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"预测质量分析\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # 基本统计\n",
    "        print(f\"预测值统计:\")\n",
    "        print(f\"  均值: {predictions_arr.mean():.6f}\")\n",
    "        print(f\"  标准差: {predictions_arr.std():.6f}\")\n",
    "        print(f\"  最小值: {predictions_arr.min():.6f}\")\n",
    "        print(f\"  最大值: {predictions_arr.max():.6f}\")\n",
    "\n",
    "        print(f\"\\n实际值统计:\")\n",
    "        print(f\"  均值: {actual_arr.mean():.6f}\")\n",
    "        print(f\"  标准差: {actual_arr.std():.6f}\")\n",
    "        print(f\"  最小值: {actual_arr.min():.6f}\")\n",
    "        print(f\"  最大值: {actual_arr.max():.6f}\")\n",
    "\n",
    "        # 分位数分析\n",
    "        prediction_quantiles = np.percentile(predictions_arr, [25, 50, 75])\n",
    "        actual_quantiles = np.percentile(actual_arr, [25, 50, 75])\n",
    "\n",
    "        print(f\"\\n分位数分析:\")\n",
    "        print(f\"  预测值 - 25%: {prediction_quantiles[0]:.6f}, 中位数: {prediction_quantiles[1]:.6f}, 75%: {prediction_quantiles[2]:.6f}\")\n",
    "        print(f\"  实际值 - 25%: {actual_quantiles[0]:.6f}, 中位数: {actual_quantiles[1]:.6f}, 75%: {actual_quantiles[2]:.6f}\")\n",
    "\n",
    "        # 信号强度分析\n",
    "        strong_buy_signals = np.sum(predictions_arr > 0.05)  # 强买入信号\n",
    "        strong_sell_signals = np.sum(predictions_arr < -0.05)  # 强卖出信号\n",
    "\n",
    "        print(f\"\\n信号强度分析:\")\n",
    "        print(f\"  强买入信号次数: {strong_buy_signals} ({strong_buy_signals/len(predictions_arr)*100:.1f}%)\")\n",
    "        print(f\"  强卖出信号次数: {strong_sell_signals} ({strong_sell_signals/len(predictions_arr)*100:.1f}%)\")\n",
    "\n",
    "        # 保存预测质量分析\n",
    "        prediction_analysis = {\n",
    "            'predictions_mean': predictions_arr.mean(),\n",
    "            'predictions_std': predictions_arr.std(),\n",
    "            'actual_mean': actual_arr.mean(),\n",
    "            'actual_std': actual_arr.std(),\n",
    "            'correlation': np.corrcoef(predictions_arr, actual_arr)[0, 1] if len(predictions_arr) > 1 else 0,\n",
    "            'direction_accuracy': np.sum((predictions_arr > 0) == (actual_arr > 0)) / len(predictions_arr)\n",
    "        }\n",
    "\n",
    "        pd.DataFrame([prediction_analysis]).to_csv(\"./prediction_quality_analysis.csv\", index=False)\n",
    "        print(\"预测质量分析已保存至: ./prediction_quality_analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f7eb1-7463-4612-b602-c832fccec2c8",
   "metadata": {
    "id": "8b2f7eb1-7463-4612-b602-c832fccec2c8"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29337615-7203-4308-bac3-906606493ab2",
   "metadata": {
    "id": "29337615-7203-4308-bac3-906606493ab2",
    "outputId": "15408a47-a67f-4c0e-d0f5-64e4d499f645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "开始在线学习模型训练和回测流程\n",
      "================================================================================\n",
      "\n",
      "1. 加载数据...\n",
      "数据维度: 2659 × 28001\n",
      "时间范围: 2015-01-02 至 2025-07-30\n",
      "目标变量: 2659 个有效样本\n",
      "\n",
      "2. 模型训练与回测...\n",
      "开始在线学习树模型策略\n",
      "\n",
      "1. 初始化在线学习模型...\n",
      "2. 初始化投资组合管理器...\n",
      "3. 初始化策略回测器...\n",
      "4. 运行回测...\n",
      "回测期间: 2018-03-05 00:00:00 到 2025-07-30 00:00:00\n",
      "回测数据量: 1862 个交易日\n",
      "进行初始模型训练...\n",
      "2018-03-05: 训练完成 - 756 样本, 23065 特征\n",
      "============================================================\n",
      "开始策略回测\n",
      "============================================================\n",
      "回测期间: 2018-03-05 至 2025-07-30\n",
      "总交易日: 1862\n",
      "进度: 1/1862 (0.1%)\n",
      "动态特征优化: 从 23065 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "警告: 连续14次亏损\n",
      "警告: 连续15次亏损\n",
      "警告: 连续16次亏损\n",
      "警告: 连续17次亏损\n",
      "警告: 连续18次亏损\n",
      "警告: 连续19次亏损\n",
      "警告: 连续20次亏损\n",
      "警告: 连续21次亏损\n",
      "警告: 连续22次亏损\n",
      "警告: 连续23次亏损\n",
      "警告: 连续24次亏损\n",
      "警告: 连续25次亏损\n",
      "警告: 连续26次亏损\n",
      "警告: 连续27次亏损\n",
      "警告: 连续28次亏损\n",
      "警告: 连续29次亏损\n",
      "警告: 连续30次亏损\n",
      "警告: 连续31次亏损\n",
      "警告: 连续32次亏损\n",
      "警告: 连续33次亏损\n",
      "警告: 连续34次亏损\n",
      "警告: 连续35次亏损\n",
      "警告: 连续36次亏损\n",
      "警告: 连续37次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续38次亏损\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "警告: 连续14次亏损\n",
      "警告: 连续15次亏损\n",
      "警告: 连续16次亏损\n",
      "警告: 连续17次亏损\n",
      "警告: 连续18次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 94/1862 (5.0%)\n",
      "警告: 连续5次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "进度: 187/1862 (10.0%)\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 280/1862 (15.0%)\n",
      "警告: 连续5次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 373/1862 (20.0%)\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "警告: 连续14次亏损\n",
      "警告: 连续15次亏损\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 466/1862 (25.0%)\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 559/1862 (30.0%)\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "警告: 连续14次亏损\n",
      "警告: 连续15次亏损\n",
      "警告: 连续16次亏损\n",
      "警告: 连续17次亏损\n",
      "警告: 连续18次亏损\n",
      "警告: 连续19次亏损\n",
      "警告: 连续20次亏损\n",
      "警告: 连续21次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 652/1862 (35.0%)\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "警告: 连续14次亏损\n",
      "警告: 连续15次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "进度: 745/1862 (40.0%)\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "警告: 连续14次亏损\n",
      "警告: 连续15次亏损\n",
      "警告: 连续16次亏损\n",
      "警告: 连续17次亏损\n",
      "警告: 连续18次亏损\n",
      "警告: 连续19次亏损\n",
      "警告: 连续20次亏损\n",
      "警告: 连续21次亏损\n",
      "警告: 连续22次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "警告: 连续14次亏损\n",
      "警告: 连续15次亏损\n",
      "警告: 连续16次亏损\n",
      "警告: 连续17次亏损\n",
      "警告: 连续18次亏损\n",
      "警告: 连续19次亏损\n",
      "警告: 连续20次亏损\n",
      "警告: 连续21次亏损\n",
      "警告: 连续22次亏损\n",
      "警告: 连续23次亏损\n",
      "警告: 连续24次亏损\n",
      "警告: 连续25次亏损\n",
      "警告: 连续26次亏损\n",
      "警告: 连续27次亏损\n",
      "警告: 连续28次亏损\n",
      "警告: 连续29次亏损\n",
      "警告: 连续30次亏损\n",
      "警告: 连续31次亏损\n",
      "警告: 连续32次亏损\n",
      "警告: 连续33次亏损\n",
      "警告: 连续34次亏损\n",
      "警告: 连续35次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续36次亏损\n",
      "警告: 连续37次亏损\n",
      "警告: 连续38次亏损\n",
      "警告: 连续39次亏损\n",
      "警告: 连续40次亏损\n",
      "警告: 连续41次亏损\n",
      "警告: 连续42次亏损\n",
      "警告: 连续43次亏损\n",
      "警告: 连续44次亏损\n",
      "警告: 连续45次亏损\n",
      "警告: 连续46次亏损\n",
      "警告: 连续47次亏损\n",
      "警告: 连续48次亏损\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "进度: 838/1862 (45.0%)\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续14次亏损\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "警告: 连续14次亏损\n",
      "警告: 连续15次亏损\n",
      "警告: 连续16次亏损\n",
      "警告: 连续17次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 931/1862 (50.0%)\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 1024/1862 (55.0%)\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 1117/1862 (60.0%)\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 1210/1862 (65.0%)\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "警告: 连续14次亏损\n",
      "警告: 连续15次亏损\n",
      "警告: 连续16次亏损\n",
      "警告: 连续17次亏损\n",
      "警告: 连续18次亏损\n",
      "警告: 连续19次亏损\n",
      "警告: 连续20次亏损\n",
      "警告: 连续21次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "进度: 1303/1862 (70.0%)\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 1396/1862 (75.0%)\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 1489/1862 (80.0%)\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "警告: 连续14次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "警告: 连续14次亏损\n",
      "警告: 连续15次亏损\n",
      "警告: 连续16次亏损\n",
      "警告: 连续17次亏损\n",
      "警告: 连续18次亏损\n",
      "进度: 1582/1862 (85.0%)\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 1675/1862 (90.0%)\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "警告: 连续14次亏损\n",
      "警告: 连续15次亏损\n",
      "警告: 连续16次亏损\n",
      "警告: 连续17次亏损\n",
      "警告: 连续18次亏损\n",
      "警告: 连续19次亏损\n",
      "警告: 连续20次亏损\n",
      "警告: 连续21次亏损\n",
      "警告: 连续22次亏损\n",
      "警告: 连续23次亏损\n",
      "警告: 连续24次亏损\n",
      "警告: 连续25次亏损\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 1768/1862 (95.0%)\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "警告: 连续5次亏损\n",
      "警告: 连续6次亏损\n",
      "警告: 连续7次亏损\n",
      "警告: 连续8次亏损\n",
      "警告: 连续9次亏损\n",
      "警告: 连续10次亏损\n",
      "警告: 连续11次亏损\n",
      "警告: 连续12次亏损\n",
      "警告: 连续13次亏损\n",
      "警告: 连续14次亏损\n",
      "警告: 连续15次亏损\n",
      "警告: 连续16次亏损\n",
      "警告: 连续17次亏损\n",
      "动态特征优化: 从 100 个特征中选择 100 个特征\n",
      "进度: 1861/1862 (99.9%)\n",
      "回测完成: 1862 次预测, 1862 次交易\n",
      "\n",
      "5. 生成回测报告...\n",
      "\n",
      "============================================================\n",
      "回测结果报告\n",
      "============================================================\n",
      "\n",
      "核心绩效指标:\n",
      "----------------------------------------\n",
      "\n",
      "收益表现:\n",
      "   总收益率: 188.89%\n",
      "   年化收益率: 14.40%\n",
      "   年化波动率: 2.65%\n",
      "   夏普比率: 5.4342\n",
      "\n",
      "风险控制:\n",
      "   最大回撤: -8.83%\n",
      "   索提诺比率: 8.4057\n",
      "\n",
      "预测质量:\n",
      "   预测相关性: 0.3817\n",
      "   方向准确率: 0.6402\n",
      "\n",
      "交易统计:\n",
      "   交易次数: 1862\n",
      "   交易胜率: 56.23%\n",
      "\n",
      "资金信息:\n",
      "   初始资本: $1,000,000\n",
      "   最终价值: $2,888,862\n",
      "   绝对收益: $1,888,862\n",
      "\n",
      "3. 结果保存...\n",
      "预测历史已保存至: ./prediction_history.csv\n",
      "特征重要性历史已保存至: ./feature_importance_history.csv\n",
      "\n",
      "特征重要性稳定性分析:\n",
      "Top 20 特征稳定性:\n",
      "  ret_21d_2633083_lag_21_roll_mean_21: 均值=0.0424, 稳定性=中\n",
      "  ret_21d_10848661: 均值=0.0371, 稳定性=中\n",
      "  ret_21d_34058542: 均值=0.0258, 稳定性=低\n",
      "  ret_21d_47440465: 均值=0.0253, 稳定性=低\n",
      "  ret_21d_2659551_lag_21_roll_mean_63: 均值=0.0233, 稳定性=中\n",
      "  ret_21d_2661992_lag_1_roll_mean_21: 均值=0.0196, 稳定性=中\n",
      "  ret_21d_2650430_roll_mean_5: 均值=0.0190, 稳定性=低\n",
      "  ret_21d_248647424_lag_5_roll_mean_5: 均值=0.0189, 稳定性=低\n",
      "  ret_21d_2656368: 均值=0.0180, 稳定性=中\n",
      "  ret_21d_47440465_lag_1: 均值=0.0171, 稳定性=低\n",
      "  financials_4256_ytd_557021597_roll_std_63: 均值=0.0168, 稳定性=低\n",
      "  ret_21d_2591273: 均值=0.0167, 稳定性=低\n",
      "  ret_21d_2659551_lag_5_roll_mean_63: 均值=0.0163, 稳定性=低\n",
      "  ret_21d_2656368_roll_mean_5: 均值=0.0153, 稳定性=中\n",
      "  financials_43898_ytd_2649739_lag_21_roll_std_63: 均值=0.0150, 稳定性=中\n",
      "  financials_4430_ytd_2619516_lag_5_roll_mean_63: 均值=0.0150, 稳定性=中\n",
      "  ret_21d_104552804_lag_21_roll_mean_63: 均值=0.0149, 稳定性=中\n",
      "  ret_21d_2623683_lag_5_roll_mean_63: 均值=0.0149, 稳定性=中\n",
      "  ret_21d_39458342_lag_5_roll_mean_63: 均值=0.0148, 稳定性=低\n",
      "  ret_21d_2649166_lag_21_roll_mean_63: 均值=0.0146, 稳定性=中\n",
      "✓ 特征稳定性分析已保存至: ./feature_stability_analysis.csv\n",
      "✓ 投资组合结果已保存至: ./portfolio_results.csv\n",
      "✓ 绩效指标已保存至: ./performance_metrics.csv\n",
      "✓ 权重历史已保存至: ./weights_history.csv\n",
      "\n",
      "============================================================\n",
      "关键绩效指标\n",
      "============================================================\n",
      "最终投资组合价值: $2,888,861.76\n",
      "初始资本: $1,000,000.00\n",
      "总收益率: 188.89%\n",
      "年化收益率: 14.40%\n",
      "年化波动率: 2.65%\n",
      "夏普比率: 5.4342\n",
      "索提诺比率: 8.4057\n",
      "最大回撤: -8.83%\n",
      "预测方向准确率: 0.6402\n",
      "交易次数: 1862\n",
      "Performance charts generated successfully!\n",
      "portfolio_value_curve.png - Portfolio value over time\n",
      "prediction_vs_actual.png - Prediction accuracy\n",
      "daily_returns.png - Daily returns\n",
      "portfolio_drawdown.png - Drawdown analysis\n",
      "cumulative_returns.png - Cumulative returns\n",
      "\n",
      "============================================================\n",
      "流程完成摘要\n",
      "============================================================\n",
      "最终绩效:\n",
      "总收益率: 188.89%\n",
      "年化收益率: 14.40%\n",
      "夏普比率: 5.4342\n",
      "最大回撤: -8.83%\n",
      "预测准确率: 0.6402\n",
      "\n",
      "交易统计:\n",
      "交易次数: 1862\n",
      "交易胜率: 56.23%\n",
      "\n",
      "资金变化:\n",
      "初始: $1,000,000\n",
      "最终: $2,888,862\n",
      "收益: $1,888,862\n",
      "\n",
      "================================================================================\n",
      "所有流程完成!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def main_model_training():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"开始在线学习模型训练和回测流程\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 1. 加载处理好的数据\n",
    "    print(\"\\n1. 加载数据...\")\n",
    "    try:\n",
    "        processed_data_path = \"./processed_data.parquet\"\n",
    "        processed_data = pd.read_parquet(processed_data_path)\n",
    "        print(f\"数据维度: {processed_data.shape[0]} × {processed_data.shape[1]}\")\n",
    "        print(f\"时间范围: {processed_data.index.min().strftime('%Y-%m-%d')} 至 {processed_data.index.max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        if 'ret_21D' in processed_data.columns:\n",
    "            target_data = processed_data['ret_21D'].dropna()\n",
    "            print(f\"目标变量: {len(target_data)} 个有效样本\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"加载数据失败: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. 运行在线学习策略\n",
    "    print(\"\\n2. 模型训练与回测...\")\n",
    "    backtest_results, model, backtester = run_online_learning_strategy(processed_data)\n",
    "\n",
    "    if backtest_results is not None:\n",
    "        # 3. 保存结果和分析\n",
    "        print(\"\\n3. 结果保存...\")\n",
    "        save_and_analyze_results(backtest_results, model, backtester)\n",
    "\n",
    "        # 显示关键结果摘要\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"流程完成摘要\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        metrics = backtest_results['metrics']\n",
    "        print(f\"最终绩效:\")\n",
    "        print(f\"总收益率: {metrics.get('Total Return (%)', 0):.2f}%\")\n",
    "        print(f\"年化收益率: {metrics.get('Annual Return (%)', 0):.2f}%\")\n",
    "        print(f\"夏普比率: {metrics.get('Sharpe Ratio', 0):.4f}\")\n",
    "        print(f\"最大回撤: {metrics.get('Max Drawdown (%)', 0):.2f}%\")\n",
    "        print(f\"预测准确率: {metrics.get('Direction Accuracy', 0):.4f}\")\n",
    "\n",
    "        print(f\"\\n交易统计:\")\n",
    "        print(f\"交易次数: {metrics.get('Number of Trades', 0)}\")\n",
    "        print(f\"交易胜率: {metrics.get('Trade Win Rate (%)', 0):.2f}%\")\n",
    "\n",
    "        print(f\"\\n资金变化:\")\n",
    "        initial = metrics.get('Initial Capital', 0)\n",
    "        final = metrics.get('Final Portfolio Value', 0)\n",
    "        print(f\"初始: ${initial:,.0f}\")\n",
    "        print(f\"最终: ${final:,.0f}\")\n",
    "        print(f\"收益: ${final - initial:,.0f}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"所有流程完成!\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "    else:\n",
    "        print(\"模型训练失败\")\n",
    "\n",
    "def run_online_learning_strategy(processed_data):\n",
    "    \"\"\"运行在线学习策略\"\"\"\n",
    "    print(\"开始在线学习树模型策略\")\n",
    "\n",
    "    # 1. 初始化在线学习模型\n",
    "    print(\"\\n1. 初始化在线学习模型...\")\n",
    "    online_model = OnlineTreeModel(\n",
    "        model_type='xgboost',\n",
    "        model_params={\n",
    "            'n_estimators': 50,  # 减少树的数量\n",
    "            'max_depth': 6,      # 降低树深度\n",
    "            'learning_rate': 0.05,  # 降低学习率\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        },\n",
    "        train_window=756,  # 增加训练窗口到3年\n",
    "        retrain_freq=42,   # 降低重新训练频率\n",
    "        prediction_horizon=21,\n",
    "        dynamic_feature_selection=True,\n",
    "        max_features=200   # 减少特征数量\n",
    "    )\n",
    "\n",
    "    # 2. 初始化投资组合管理器\n",
    "    print(\"2. 初始化投资组合管理器...\")\n",
    "    portfolio_manager = AdvancedPortfolioManager(\n",
    "        initial_capital=1000000,\n",
    "        max_position=0.02,      # 2%最大仓位\n",
    "        transaction_cost=0.005, # 0.5%交易成本\n",
    "        kelly_fraction=0.08,    # 8%凯利分数\n",
    "        min_volatility=0.03,    # 3%最小波动率\n",
    "        prediction_threshold=0.01  # 1%预测阈值\n",
    "    )\n",
    "\n",
    "    # 3. 初始化回测器\n",
    "    print(\"3. 初始化策略回测器...\")\n",
    "    backtester = EnhancedStrategyBacktester(online_model, portfolio_manager)\n",
    "\n",
    "    # 4. 运行回测\n",
    "    print(\"4. 运行回测...\")\n",
    "    # 使用后70%的数据进行回测，前20%用于初始训练\n",
    "    split_idx = int(len(processed_data) * 0.3)\n",
    "    start_date = processed_data.index[split_idx]\n",
    "    end_date = processed_data.index[-1]\n",
    "\n",
    "    print(f\"回测期间: {start_date} 到 {end_date}\")\n",
    "    print(f\"回测数据量: {len(processed_data[processed_data.index >= start_date])} 个交易日\")\n",
    "\n",
    "    # 初始训练\n",
    "    print(\"进行初始模型训练...\")\n",
    "    initial_success = online_model.train_model(processed_data, start_date, initial_training=True)\n",
    "    if not initial_success:\n",
    "        print(\"初始训练失败，调整参数重试...\")\n",
    "        # 如果初始训练失败，尝试使用更大的窗口\n",
    "        online_model.train_window = min(online_model.train_window, len(processed_data) // 2)\n",
    "        initial_success = online_model.train_model(processed_data, start_date, initial_training=True)\n",
    "\n",
    "    if initial_success:\n",
    "        backtest_results = backtester.run_enhanced_backtest(processed_data, start_date, end_date)\n",
    "\n",
    "        # 生成报告\n",
    "        print(\"\\n5. 生成回测报告...\")\n",
    "        backtester.generate_enhanced_report(backtest_results)\n",
    "\n",
    "        return backtest_results, online_model, backtester\n",
    "    else:\n",
    "        print(\"初始训练失败，无法进行回测\")\n",
    "        return None, None, None\n",
    "\n",
    "def save_and_analyze_results(backtest_results, model, backtester):\n",
    "    \"\"\"保存结果并进行详细分析\"\"\"\n",
    "\n",
    "    # 1. 保存预测历史\n",
    "    predictions_df = pd.DataFrame(model.prediction_history)\n",
    "    predictions_df.to_csv(\"./prediction_history.csv\", index=False)\n",
    "    print(\"预测历史已保存至: ./prediction_history.csv\")\n",
    "\n",
    "    # 2. 保存特征重要性\n",
    "    if model.feature_importance_history:\n",
    "        feature_importance_df = pd.concat(model.feature_importance_history)\n",
    "        feature_importance_df.to_csv(\"./feature_importance_history.csv\", index=False)\n",
    "        print(\"特征重要性历史已保存至: ./feature_importance_history.csv\")\n",
    "\n",
    "        # 分析特征重要性稳定性\n",
    "        analyze_feature_stability(feature_importance_df)\n",
    "\n",
    "    # 3. 保存投资组合结果\n",
    "    portfolio_results = pd.DataFrame({\n",
    "        'date': backtest_results['portfolio_dates'],\n",
    "        'portfolio_value': backtest_results['portfolio_values']\n",
    "    })\n",
    "    portfolio_results.to_csv(\"./portfolio_results.csv\", index=False)\n",
    "    print(\"✓ 投资组合结果已保存至: ./portfolio_results.csv\")\n",
    "\n",
    "    # 4. 保存绩效指标\n",
    "    metrics_df = pd.DataFrame([backtest_results['metrics']])\n",
    "    metrics_df.to_csv(\"./performance_metrics.csv\", index=False)\n",
    "    print(\"✓ 绩效指标已保存至: ./performance_metrics.csv\")\n",
    "\n",
    "    # 5. 保存权重历史\n",
    "    if 'weights_history' in backtest_results:\n",
    "        weights_history = pd.DataFrame(backtest_results['weights_history'])\n",
    "        weights_history.to_csv(\"./weights_history.csv\", index=False)\n",
    "        print(\"✓ 权重历史已保存至: ./weights_history.csv\")\n",
    "\n",
    "    # 6. 显示关键结果\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"关键绩效指标\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    metrics = backtest_results['metrics']\n",
    "    print(f\"最终投资组合价值: ${metrics.get('Final Portfolio Value', 0):,.2f}\")\n",
    "    print(f\"初始资本: ${backtester.portfolio_manager.initial_capital:,.2f}\")\n",
    "    print(f\"总收益率: {metrics.get('Total Return (%)', 0):.2f}%\")\n",
    "    print(f\"年化收益率: {metrics.get('Annual Return (%)', 0):.2f}%\")\n",
    "    print(f\"年化波动率: {metrics.get('Annual Volatility (%)', 0):.2f}%\")\n",
    "    print(f\"夏普比率: {metrics.get('Sharpe Ratio', 0):.4f}\")\n",
    "    print(f\"索提诺比率: {metrics.get('Sortino Ratio', 0):.4f}\")\n",
    "    print(f\"最大回撤: {metrics.get('Max Drawdown (%)', 0):.2f}%\")\n",
    "    print(f\"预测方向准确率: {metrics.get('Direction Accuracy', 0):.4f}\")\n",
    "    print(f\"交易次数: {metrics.get('Number of Trades', 0)}\")\n",
    "\n",
    "    # 7. 生成可视化图表\n",
    "    generate_performance_charts(backtest_results)\n",
    "\n",
    "def analyze_feature_stability(feature_importance_df):\n",
    "    \"\"\"分析特征重要性稳定性\"\"\"\n",
    "    print(\"\\n特征重要性稳定性分析:\")\n",
    "\n",
    "    # 按特征分组，计算重要性的均值和标准差\n",
    "    feature_stability = feature_importance_df.groupby('feature')['importance'].agg(['mean', 'std', 'count']).reset_index()\n",
    "    feature_stability['cv'] = feature_stability['std'] / feature_stability['mean']  # 变异系数\n",
    "\n",
    "    # 选择最重要的特征进行分析\n",
    "    top_features = feature_stability.nlargest(20, 'mean')\n",
    "\n",
    "    print(\"Top 20 特征稳定性:\")\n",
    "    for _, row in top_features.iterrows():\n",
    "        stability = \"高\" if row['cv'] < 0.5 else \"中\" if row['cv'] < 1.0 else \"低\"\n",
    "        print(f\"  {row['feature']}: 均值={row['mean']:.4f}, 稳定性={stability}\")\n",
    "\n",
    "    # 保存特征稳定性分析\n",
    "    feature_stability.to_csv(\"./feature_stability_analysis.csv\", index=False)\n",
    "    print(\"✓ 特征稳定性分析已保存至: ./feature_stability_analysis.csv\")\n",
    "\n",
    "def generate_performance_charts(backtest_results):\n",
    "    \"\"\"Generate performance charts\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "\n",
    "        # Set style and parameters\n",
    "        plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Helvetica']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "        # 1. Portfolio Value Curve\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(backtest_results['portfolio_dates'], backtest_results['portfolio_values'],\n",
    "                linewidth=2, color='#2E86AB')\n",
    "        plt.title('Portfolio Value Over Time', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Portfolio Value ($)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # Format y-axis for better readability\n",
    "        max_val = max(backtest_results['portfolio_values'])\n",
    "        if max_val > 1e6:\n",
    "            plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.1f}M'))\n",
    "        else:\n",
    "            plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('./portfolio_value_curve.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # 2. Prediction vs Actual Scatter Plot\n",
    "        if 'predictions' in backtest_results and 'actual_returns' in backtest_results:\n",
    "            predictions = backtest_results['predictions']\n",
    "            actual_returns = backtest_results['actual_returns']\n",
    "\n",
    "            if len(predictions) > 0 and len(actual_returns) > 0:\n",
    "                min_len = min(len(predictions), len(actual_returns))\n",
    "                plt.figure(figsize=(10, 6))\n",
    "\n",
    "                # Create scatter plot with some styling\n",
    "                plt.scatter(actual_returns[:min_len], predictions[:min_len],\n",
    "                           alpha=0.6, s=30, color='#A23B72')\n",
    "\n",
    "                # Add perfect prediction line\n",
    "                min_val = min(min(actual_returns), min(predictions))\n",
    "                max_val = max(max(actual_returns), max(predictions))\n",
    "                plt.plot([min_val, max_val], [min_val, max_val], 'r--',\n",
    "                        linewidth=2, alpha=0.8, label='Perfect Prediction')\n",
    "\n",
    "                plt.xlabel('Actual Returns')\n",
    "                plt.ylabel('Predicted Returns')\n",
    "                plt.title('Predicted vs Actual Returns', fontsize=14, fontweight='bold')\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig('./prediction_vs_actual.png', dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "        # 3. Daily Returns Chart\n",
    "        portfolio_values = backtest_results['portfolio_values']\n",
    "        if len(portfolio_values) > 1:\n",
    "            daily_returns = []\n",
    "            for i in range(1, len(portfolio_values)):\n",
    "                daily_return = (portfolio_values[i] - portfolio_values[i-1]) / portfolio_values[i-1]\n",
    "                daily_returns.append(daily_return)\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(backtest_results['portfolio_dates'][1:], daily_returns,\n",
    "                    linewidth=1, color='#F18F01', alpha=0.8)\n",
    "            plt.title('Daily Returns', fontsize=14, fontweight='bold')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Daily Return')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.2%}'))\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('./daily_returns.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        # 4. Drawdown Chart\n",
    "        if len(portfolio_values) > 0:\n",
    "            # Calculate drawdown\n",
    "            portfolio_series = pd.Series(portfolio_values)\n",
    "            rolling_max = portfolio_series.expanding().max()\n",
    "            drawdown = (portfolio_series - rolling_max) / rolling_max\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.fill_between(backtest_results['portfolio_dates'], drawdown * 100, 0,\n",
    "                           alpha=0.3, color='#C73E1D', label='Drawdown')\n",
    "            plt.plot(backtest_results['portfolio_dates'], drawdown * 100,\n",
    "                   color='#C73E1D', linewidth=1, alpha=0.8)\n",
    "            plt.title('Portfolio Drawdown Over Time', fontsize=14, fontweight='bold')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Drawdown (%)')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('./portfolio_drawdown.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        # 5. Cumulative Returns Chart\n",
    "        if len(portfolio_values) > 1:\n",
    "            initial_value = portfolio_values[0]\n",
    "            cumulative_returns = [(value - initial_value) / initial_value for value in portfolio_values]\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(backtest_results['portfolio_dates'], cumulative_returns,\n",
    "                    linewidth=2, color='#2E86AB')\n",
    "            plt.title('Cumulative Returns', fontsize=14, fontweight='bold')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Cumulative Return')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.2%}'))\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('./cumulative_returns.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        print(\"Performance charts generated successfully!\")\n",
    "        print(\"portfolio_value_curve.png - Portfolio value over time\")\n",
    "        print(\"prediction_vs_actual.png - Prediction accuracy\")\n",
    "        print(\"daily_returns.png - Daily returns\")\n",
    "        print(\"portfolio_drawdown.png - Drawdown analysis\")\n",
    "        print(\"cumulative_returns.png - Cumulative returns\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"Warning: matplotlib or seaborn not installed, cannot generate charts\")\n",
    "        print(\"Please run: pip install matplotlib seaborn\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating charts: {e}\")\n",
    "\n",
    "# 运行模型训练\n",
    "if __name__ == \"__main__\":\n",
    "    # 测试配置 - 简洁输出\n",
    "    OutputConfig.VERBOSE = False\n",
    "    OutputConfig.SHOW_PROGRESS = True\n",
    "    OutputConfig.SHOW_FEATURE_DETAILS = False\n",
    "    OutputConfig.SHOW_TRAINING_DETAILS = False\n",
    "\n",
    "    main_model_training()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
